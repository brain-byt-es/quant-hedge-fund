"""
QS Connect - Zipline Bundle Builder

Creates Zipline-compatible data bundles from the DuckDB database.
"""

from pathlib import Path
from typing import Optional
from datetime import date
import os

import polars as pl
import pandas as pd
from loguru import logger

from qsconnect.database.duckdb_manager import DuckDBManager


class ZiplineBundler:
    """
    Builds Zipline-compatible data bundles.
    
    Zipline Reloaded requires data in a specific format for its
    event-based backtesting engine. This class handles the conversion
    from DuckDB to Zipline bundles.
    """
    
    def __init__(self, db_manager: DuckDBManager):
        """
        Initialize Zipline bundler.
        
        Args:
            db_manager: DuckDB manager instance
        """
        self._db_manager = db_manager
        self._bundle_dir = Path.home() / ".zipline" / "custom_bundles"
        self._bundle_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"Zipline bundler initialized. Bundle dir: {self._bundle_dir}")
    
    def build_bundle(
        self,
        bundle_name: str = "historical_prices_fmp",
        start_date: Optional[date] = None,
        end_date: Optional[date] = None,
    ) -> Path:
        """
        Build a Zipline bundle from database data.
        
        Args:
            bundle_name: Name for the bundle
            start_date: Start date for data inclusion
            end_date: End date for data inclusion
            
        Returns:
            Path to the created bundle directory
        """
        logger.info(f"Building Zipline bundle: {bundle_name}")
        
        # Get price data from database
        prices = self._db_manager.get_prices(
            start_date=start_date.isoformat() if start_date else None,
            end_date=end_date.isoformat() if end_date else None,
        )
        
        if prices.is_empty():
            logger.warning("No price data available for bundle")
            return Path()
        
        # Create bundle directory
        bundle_path = self._bundle_dir / bundle_name
        bundle_path.mkdir(parents=True, exist_ok=True)
        
        # Write price data in Zipline format
        self._write_daily_bundle(prices, bundle_path)
        
        # Write asset metadata
        self._write_asset_metadata(prices, bundle_path)
        
        logger.info(f"Bundle created: {bundle_path}")
        return bundle_path
    
    def _write_daily_bundle(self, prices: pl.DataFrame, bundle_path: Path) -> None:
        """Write daily price data in Zipline CSVDIR format."""
        # Convert to pandas for Zipline compatibility
        df = prices.to_pandas()
        
        # Ensure required columns
        required_cols = ["symbol", "date", "open", "high", "low", "close", "volume"]
        df = df[required_cols].copy()
        
        # Convert date to datetime
        df["date"] = pd.to_datetime(df["date"])
        
        # Zipline expects: date,open,high,low,close,volume,dividend,split
        # We add dummy dividend/split if missing
        if "dividend" not in df.columns:
            df["dividend"] = 0.0
        if "split" not in df.columns:
            df["split"] = 1.0
            
        daily_path = bundle_path / "daily"
        daily_path.mkdir(parents=True, exist_ok=True)
        
        # Write individual CSVs
        count = 0
        for symbol, group in df.groupby("symbol"):
            filename = f"{symbol}.csv"
            # Zipline expects date as index? No, just a column named 'date'
            group.to_csv(daily_path / filename, index=False)
            count += 1
        
        logger.info(f"Wrote {count} symbol CSVs to {daily_path}")
    
    def _write_asset_metadata(self, prices: pl.DataFrame, bundle_path: Path) -> None:
        # csvdir doesn't need explicit metadata file usually, it infers from CSVs.
        # But we keep it if we write a custom ingestor later.
        pass

    def register_bundle(self, bundle_name: str) -> None:
        """
        Register a bundle with Zipline via ~/.zipline/extension.py
        
        Uses a custom ingest function to ensure robust date parsing.
        """
        extension_path = Path.home() / ".zipline" / "extension.py"
        extension_path.parent.mkdir(parents=True, exist_ok=True)
        
        bundle_path = self._bundle_dir / bundle_name / "daily"
        
        # Create custom ingest code
        extension_code = f'''
# Auto-generated by QS Connect
from zipline.data.bundles import register
import pandas as pd
import os

def custom_csv_ingest(environ,
                      asset_db_writer,
                      minute_bar_writer,
                      daily_bar_writer,
                      adjustment_writer,
                      calendar,
                      start_session,
                      end_session,
                      cache,
                      show_progress,
                      output_dir):
    
    path = r"{bundle_path}"
    divs_splits = {{'divs': pd.DataFrame(columns=['sid', 'amount', 'ex_date', 'record_date', 'declared_date', 'pay_date']),
                   'splits': pd.DataFrame(columns=['sid', 'ratio', 'effective_date'])}}
    
    data = []
    metadata = []
    
    # List files
    try:
        files = [f for f in os.listdir(path) if f.endswith(".csv")]
    except FileNotFoundError:
        return # Nothing to ingest
        
    for file in files:
        symbol = file.split(".")[0]
        
        # KEY FIX: Explicitly parse dates
        df = pd.read_csv(os.path.join(path, file), index_col='date', parse_dates=['date'])
        df = df.sort_index()
        
        if df.empty: continue
        
        start_date = df.index[0]
        end_date = df.index[-1]
        
        # Auto-assign SID
        sid = len(metadata) 
        
        metadata.append((sid, symbol, start_date, end_date, start_date, end_date, 'NYSE', 'QSConnect'))
        data.append((sid, df))
    
    # Write metadata
    metadata_df = pd.DataFrame(metadata, columns=[
        'sid', 'symbol', 'start_date', 'end_date', 'auto_close_date', 
        'exchange', 'exchange_full', 'asset_name'
    ])
    asset_db_writer.write(metadata_df)
    
    # Write data
    daily_bar_writer.write(data, show_progress=show_progress)
    
    # Write empty adjustments (required)
    adjustment_writer.write(divs_splits['splits'], divs_splits['divs'])

# Register {bundle_name} bundle
register(
    "{bundle_name}",
    custom_csv_ingest,
    calendar_name="NYSE", 
)
'''
        # Ensure file exists
        if not extension_path.exists():
            extension_path.touch()
            
        content = extension_path.read_text()
        if f'register(\n    "{bundle_name}"' in content:
             pass # Already registered
        else:
             with open(extension_path, "a") as f:
                f.write(extension_code)
             logger.info(f"Registered bundle: {bundle_name}")

    def ingest_bundle(self, bundle_name: str) -> None:
        """
        Ingest a bundle into Zipline.
        """
        import subprocess
        
        # Ensure registration exists before ingestion
        self.register_bundle(bundle_name)
        
        logger.info(f"Ingesting bundle: {bundle_name}")
        
        try:
            result = subprocess.run(
                ["zipline", "ingest", "-b", bundle_name],
                capture_output=True,
                text=True,
                check=True,
            )
            logger.info(f"Bundle ingested successfully: {result.stdout}")
        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to ingest bundle: {e.stderr}")
            raise
    
    def list_bundles(self) -> list:
        """List available bundles."""
        bundles = [d.name for d in self._bundle_dir.iterdir() if d.is_dir()]
        return bundles
