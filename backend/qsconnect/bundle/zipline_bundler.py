"""
QS Connect - Zipline Bundle Builder

Creates Zipline-compatible data bundles from the DuckDB database.
"""

from pathlib import Path
from typing import Optional
from datetime import date
import os
import sys

import polars as pl
import pandas as pd
from loguru import logger

from qsconnect.database.duckdb_manager import DuckDBManager


class ZiplineBundler:
    """
    Builds Zipline-compatible data bundles.
    """
    
    def __init__(self, db_manager: DuckDBManager):
        """
        Initialize Zipline bundler with project-local paths.
        """
        self._db_manager = db_manager
        
        # Determine project root
        cwd = Path.cwd()
        if cwd.name == "backend":
            project_root = cwd.parent
        else:
            project_root = cwd
            
        self._zipline_root = project_root / "data" / "zipline"
        self._bundle_dir = self._zipline_root / "custom_bundles"
        
        self._zipline_root.mkdir(parents=True, exist_ok=True)
        self._bundle_dir.mkdir(parents=True, exist_ok=True)
        
        # Set ZIPLINE_ROOT for current process
        os.environ["ZIPLINE_ROOT"] = str(self._zipline_root.absolute())
        
        logger.info(f"Zipline bundler initialized. Root: {self._zipline_root}")

    def build_bundle(
        self,
        bundle_name: str = "historical_prices_fmp",
        start_date: Optional[date] = None,
        end_date: Optional[date] = None,
        symbols: Optional[list] = None,
    ) -> Path:
        """
        Build a Zipline bundle from database data.
        """
        logger.info(f"Building Zipline bundle: {bundle_name}")
        
        # Get price data from database
        if symbols:
            # Construct symbol filter SQL
            sym_list = "', '".join(symbols)
            sql = f"SELECT symbol, date, open, high, low, close, volume FROM historical_prices_fmp WHERE symbol IN ('{sym_list}')"
            if start_date: sql += f" AND date >= '{start_date.isoformat()}'"
            if end_date: sql += f" AND date <= '{end_date.isoformat()}'"
            sql += " ORDER BY symbol, date"
            prices = self._db_manager.query(sql)
        else:
            prices = self._db_manager.get_prices(
                start_date=start_date.isoformat() if start_date else None,
                end_date=end_date.isoformat() if end_date else None,
            )
        
        if prices.is_empty():
            logger.warning("No price data available for bundle")
            return Path()
        
        # Create bundle directory
        bundle_path = self._bundle_dir / bundle_name
        bundle_path.mkdir(parents=True, exist_ok=True)
        
        # Write price data in Zipline format
        self._write_daily_bundle(prices, bundle_path)
        
        logger.info(f"Bundle CSVs created at: {bundle_path}")
        return bundle_path
    
    def _write_daily_bundle(self, prices: pl.DataFrame, bundle_path: Path) -> None:
        """Write daily price data in Zipline CSVDIR format."""
        df = prices.to_pandas()
        required_cols = ["symbol", "date", "open", "high", "low", "close", "volume"]
        df = df[required_cols].copy()
        df["date"] = pd.to_datetime(df["date"])
        
        daily_path = bundle_path / "daily"
        daily_path.mkdir(parents=True, exist_ok=True)
        
        count = 0
        for symbol, group in df.groupby("symbol"):
            filename = f"{symbol}.csv"
            group.to_csv(daily_path / filename, index=False)
            count += 1
        
        logger.info(f"Wrote {count} symbol CSVs to {daily_path}")

    def register_bundle(self, bundle_name: str) -> None:
        """
        Register a bundle with Zipline via local extension.py.
        """
        extension_path = self._zipline_root / "extension.py"
        bundle_path = self._bundle_dir / bundle_name / "daily"
        
        # Create custom ingest code
        extension_code = f'''
# Auto-generated by QS Connect
from zipline.data.bundles import register
import pandas as pd
import os

def custom_csv_ingest(environ,
                      asset_db_writer,
                      minute_bar_writer,
                      daily_bar_writer,
                      adjustment_writer,
                      calendar,
                      start_session,
                      end_session,
                      cache,
                      show_progress,
                      output_dir):
    
    path = r"{bundle_path}"
    divs_splits = {{'divs': pd.DataFrame(columns=['sid', 'amount', 'ex_date', 'record_date', 'declared_date', 'pay_date']),
                   'splits': pd.DataFrame(columns=['sid', 'ratio', 'effective_date'])}}
    
    data = []
    metadata = []
    
    try:
        files = [f for f in os.listdir(path) if f.endswith(".csv")]
    except FileNotFoundError:
        return
        
    for file in files:
        symbol = file.split(".")[0]
        try:
            df = pd.read_csv(os.path.join(path, file), index_col='date', parse_dates=['date'])
            if df.empty: continue
            
            df = df.sort_index()
            
            if df.index.tz is None:
                df.index = df.index.tz_localize('UTC')
            else:
                df.index = df.index.tz_convert('UTC')
            
            start_dt = df.index[0]
            end_dt = df.index[-1]
            
            # Align sessions with UTC
            try:
                sessions = calendar.sessions_in_range(start_dt.tz_localize(None), end_dt.tz_localize(None))
                sessions = sessions.tz_localize('UTC')
            except: continue
                
            df = df.reindex(sessions)
            # Fix: forward fill then backward fill to ensure NO NaNs exist in the session range
            df['close'] = df['close'].ffill().bfill()
            df['open'] = df['open'].fillna(df['close'])
            df['high'] = df['high'].fillna(df['close'])
            df['low'] = df['low'].fillna(df['close'])
            df['volume'] = df['volume'].fillna(0)
            
            # CRITICAL: We MUST NOT use dropna() here because it breaks the session alignment
            # length of df must match length of sessions exactly.
            
            if df.empty: continue
            
            sid = len(metadata) 
            metadata.append({{
                'sid': sid,
                'symbol': symbol,
                'asset_name': symbol,
                'start_date': df.index[0],
                'end_date': df.index[-1],
                'first_traded': df.index[0],
                'auto_close_date': df.index[-1],
                'exchange': 'NYSE'
            }})
            data.append((sid, df))
        except: continue
    
    if metadata:
        equities_df = pd.DataFrame(metadata)
        equities_df['sid'] = equities_df['sid'].astype(int)
        equities_df = equities_df.set_index('sid')
        
        exchanges_df = pd.DataFrame([
            {{'exchange': 'NYSE', 'canonical_name': 'NYSE', 'country_code': 'US'}}
        ]).set_index('exchange')
        
        asset_db_writer.write(equities=equities_df, exchanges=exchanges_df)
        daily_bar_writer.write(data, show_progress=show_progress)
        adjustment_writer.write(divs_splits['splits'], divs_splits['divs'])

register(
    "{bundle_name}",
    custom_csv_ingest,
    calendar_name="NYSE", 
)
'''
        with open(extension_path, "w") as f:
            f.write(extension_code)
        logger.info(f"Registered bundle locally: {extension_path}")

    def ingest_bundle(self, bundle_name: str) -> None:
        """
        Ingest a bundle into Zipline using local project root.
        """
        self.register_bundle(bundle_name)
        
        logger.info(f"Ingesting bundle locally: {bundle_name}")
        
        try:
            # Find zipline binary
            venv_bin = Path(sys.executable).parent
            zipline_bin = venv_bin / "zipline"
            
            # CRITICAL: Pass ZIPLINE_ROOT to the subprocess
            env = os.environ.copy()
            env["ZIPLINE_ROOT"] = str(self._zipline_root.absolute())
            
            import subprocess
            result = subprocess.run(
                [str(zipline_bin), "ingest", "-b", bundle_name],
                capture_output=True,
                text=True,
                check=True,
                env=env
            )
            logger.info(f"Bundle ingested successfully to project folder.")
        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to ingest bundle: {e.stderr}")
            raise

    def list_bundles(self) -> list:
        """List available bundles in the local project directory."""
        if not self._bundle_dir.exists(): return []
        bundles = [d.name for d in self._bundle_dir.iterdir() if d.is_dir()]
        return bundles
